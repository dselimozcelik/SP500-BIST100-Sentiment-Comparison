# src/sentiment_analyzer.py
"""
FinBERT ile Finansal Haber Sentiment Analizi ModÃ¼lÃ¼
ProsusAI/finbert modelini kullanÄ±r - finansal metinler iÃ§in Ã¶zel eÄŸitilmiÅŸ BERT.
"""

import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from scipy.special import softmax
from tqdm import tqdm
import os
import warnings
warnings.filterwarnings('ignore')

# --- AYARLAR ---
MODEL_NAME = "ProsusAI/finbert"  # Finansal sentiment iÃ§in en iyi model
DATA_DIR = "data"
NEWS_FILE = os.path.join(DATA_DIR, "bist_financial_news_v3.csv")
OUTPUT_FILE = os.path.join(DATA_DIR, "news_with_sentiment.csv")

# Sentiment etiketleri
LABELS = ['negative', 'neutral', 'positive']


class FinBERTSentimentAnalyzer:
    """
    FinBERT tabanlÄ± finansal sentiment analizi sÄ±nÄ±fÄ±.
    """
    
    def __init__(self, model_name: str = MODEL_NAME, device: str = None):
        """
        Args:
            model_name: Hugging Face model adÄ±
            device: 'cuda' veya 'cpu' (None ise otomatik seÃ§er)
        """
        print(f"ðŸ¤– FinBERT Modeli YÃ¼kleniyor: {model_name}")
        
        # Device seÃ§imi
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
        print(f"   Device: {self.device}")
        
        # Model ve tokenizer yÃ¼kle
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
        self.model.to(self.device)
        self.model.eval()
        
        print("âœ… Model baÅŸarÄ±yla yÃ¼klendi!")
    
    def analyze_single(self, text: str) -> dict:
        """
        Tek bir metin iÃ§in sentiment analizi yapar.
        
        Args:
            text: Analiz edilecek metin (haber baÅŸlÄ±ÄŸÄ± veya iÃ§erik)
        
        Returns:
            dict: {
                'sentiment': 'positive'/'negative'/'neutral',
                'confidence': float (0-1),
                'positive_prob': float,
                'negative_prob': float,
                'neutral_prob': float,
                'sentiment_score': float (-1 to +1)
            }
        """
        if not text or pd.isna(text):
            return {
                'sentiment': 'neutral',
                'confidence': 0.0,
                'positive_prob': 0.33,
                'negative_prob': 0.33,
                'neutral_prob': 0.34,
                'sentiment_score': 0.0
            }
        
        # Tokenize
        inputs = self.tokenizer(
            text,
            return_tensors='pt',
            truncation=True,
            max_length=512,
            padding=True
        ).to(self.device)
        
        # Ä°nference
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits.cpu().numpy()[0]
        
        # Softmax ile olasÄ±lÄ±klara Ã§evir
        probs = softmax(logits)
        
        # En yÃ¼ksek olasÄ±lÄ±klÄ± sÄ±nÄ±f
        predicted_class = np.argmax(probs)
        sentiment = LABELS[predicted_class]
        confidence = float(probs[predicted_class])
        
        # Sentiment skoru: -1 (Ã§ok negatif) ile +1 (Ã§ok pozitif) arasÄ±
        # positive_prob - negative_prob formÃ¼lÃ¼
        sentiment_score = float(probs[2] - probs[0])  # positive - negative
        
        return {
            'sentiment': sentiment,
            'confidence': confidence,
            'positive_prob': float(probs[2]),
            'negative_prob': float(probs[0]),
            'neutral_prob': float(probs[1]),
            'sentiment_score': sentiment_score
        }
    
    def analyze_batch(self, texts: list, batch_size: int = 16) -> list:
        """
        Batch halinde sentiment analizi yapar (daha hÄ±zlÄ±).
        
        Args:
            texts: Metin listesi
            batch_size: Her batch'teki metin sayÄ±sÄ±
        
        Returns:
            list: Her metin iÃ§in sentiment sonucu
        """
        results = []
        
        for i in tqdm(range(0, len(texts), batch_size), desc="Sentiment Analizi"):
            batch_texts = texts[i:i + batch_size]
            
            # BoÅŸ/NaN metinleri filtrele
            valid_texts = []
            valid_indices = []
            for j, text in enumerate(batch_texts):
                if text and not pd.isna(text):
                    valid_texts.append(str(text))
                    valid_indices.append(j)
            
            # BoÅŸ batch kontrolÃ¼
            if not valid_texts:
                for _ in batch_texts:
                    results.append({
                        'sentiment': 'neutral',
                        'confidence': 0.0,
                        'positive_prob': 0.33,
                        'negative_prob': 0.33,
                        'neutral_prob': 0.34,
                        'sentiment_score': 0.0
                    })
                continue
            
            # Tokenize
            inputs = self.tokenizer(
                valid_texts,
                return_tensors='pt',
                truncation=True,
                max_length=512,
                padding=True
            ).to(self.device)
            
            # Ä°nference
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits.cpu().numpy()
            
            # Her metin iÃ§in sonuÃ§ oluÅŸtur
            batch_results = [None] * len(batch_texts)
            
            for k, idx in enumerate(valid_indices):
                probs = softmax(logits[k])
                predicted_class = np.argmax(probs)
                
                batch_results[idx] = {
                    'sentiment': LABELS[predicted_class],
                    'confidence': float(probs[predicted_class]),
                    'positive_prob': float(probs[2]),
                    'negative_prob': float(probs[0]),
                    'neutral_prob': float(probs[1]),
                    'sentiment_score': float(probs[2] - probs[0])
                }
            
            # BoÅŸ olanlar iÃ§in default
            for j in range(len(batch_results)):
                if batch_results[j] is None:
                    batch_results[j] = {
                        'sentiment': 'neutral',
                        'confidence': 0.0,
                        'positive_prob': 0.33,
                        'negative_prob': 0.33,
                        'neutral_prob': 0.34,
                        'sentiment_score': 0.0
                    }
            
            results.extend(batch_results)
        
        return results
    
    def analyze_dataframe(self, df: pd.DataFrame, text_column: str = 'title',
                          batch_size: int = 16) -> pd.DataFrame:
        """
        DataFrame'deki haberlere sentiment analizi uygular.
        
        Args:
            df: Haber verisi iÃ§eren DataFrame
            text_column: Analiz edilecek sÃ¼tun adÄ±
            batch_size: Batch boyutu
        
        Returns:
            DataFrame: Sentiment sÃ¼tunlarÄ± eklenmiÅŸ DataFrame
        """
        print(f"\nðŸ“Š {len(df)} haber iÃ§in sentiment analizi baÅŸlÄ±yor...")
        
        # Metinleri al
        texts = df[text_column].tolist()
        
        # Batch analiz
        results = self.analyze_batch(texts, batch_size)
        
        # SonuÃ§larÄ± DataFrame'e ekle
        df_result = df.copy()
        df_result['sentiment'] = [r['sentiment'] for r in results]
        df_result['sentiment_confidence'] = [r['confidence'] for r in results]
        df_result['positive_prob'] = [r['positive_prob'] for r in results]
        df_result['negative_prob'] = [r['negative_prob'] for r in results]
        df_result['neutral_prob'] = [r['neutral_prob'] for r in results]
        df_result['sentiment_score'] = [r['sentiment_score'] for r in results]
        
        # Ä°statistikler
        print("\nðŸ“ˆ Sentiment DaÄŸÄ±lÄ±mÄ±:")
        print(df_result['sentiment'].value_counts())
        print(f"\nOrtalama Sentiment Skoru: {df_result['sentiment_score'].mean():.3f}")
        
        return df_result


def analyze_news_file(input_file: str = NEWS_FILE, output_file: str = OUTPUT_FILE,
                      text_column: str = 'title') -> pd.DataFrame:
    """
    CSV dosyasÄ±ndaki haberleri analiz eder ve sonucu kaydeder.
    """
    print(f"ðŸ“‚ Haber dosyasÄ± okunuyor: {input_file}")
    
    if not os.path.exists(input_file):
        print(f"âŒ Dosya bulunamadÄ±: {input_file}")
        return pd.DataFrame()
    
    # Veriyi yÃ¼kle
    df = pd.read_csv(input_file)
    print(f"   {len(df)} haber bulundu.")
    
    # Analyzer oluÅŸtur
    analyzer = FinBERTSentimentAnalyzer()
    
    # Analiz et
    df_result = analyzer.analyze_dataframe(df, text_column=text_column)
    
    # Kaydet
    df_result.to_csv(output_file, index=False)
    print(f"\nðŸ’¾ SonuÃ§ kaydedildi: {output_file}")
    
    return df_result


def get_daily_sentiment(df: pd.DataFrame, date_column: str = 'date') -> pd.DataFrame:
    """
    GÃ¼nlÃ¼k ortalama sentiment hesaplar.
    AynÄ± gÃ¼ndeki tÃ¼m haberlerin sentiment'ini birleÅŸtirir.
    
    Args:
        df: Sentiment analizi yapÄ±lmÄ±ÅŸ haber DataFrame'i
        date_column: Tarih sÃ¼tunu adÄ±
    
    Returns:
        DataFrame: GÃ¼nlÃ¼k sentiment Ã¶zeti
    """
    print("\nðŸ“… GÃ¼nlÃ¼k sentiment hesaplanÄ±yor...")
    
    # Tarih formatÄ±nÄ± dÃ¼zelt
    df_copy = df.copy()
    df_copy[date_column] = pd.to_datetime(df_copy[date_column]).dt.date
    
    # GÃ¼nlÃ¼k agregasyon
    daily = df_copy.groupby(date_column).agg({
        'sentiment_score': ['mean', 'std', 'count'],
        'positive_prob': 'mean',
        'negative_prob': 'mean',
        'neutral_prob': 'mean',
        'title': 'count'  # Haber sayÄ±sÄ±
    }).reset_index()
    
    # SÃ¼tun adlarÄ±nÄ± dÃ¼zelt
    daily.columns = [date_column, 'avg_sentiment', 'sentiment_std', 'sentiment_count',
                     'avg_positive', 'avg_negative', 'avg_neutral', 'news_count']
    
    # Sentiment kategorisi (gÃ¼nlÃ¼k dominant sentiment)
    def categorize(score):
        if score > 0.1:
            return 'positive'
        elif score < -0.1:
            return 'negative'
        else:
            return 'neutral'
    
    daily['daily_sentiment_category'] = daily['avg_sentiment'].apply(categorize)
    
    print(f"   {len(daily)} gÃ¼n iÃ§in sentiment hesaplandÄ±.")
    
    return daily


if __name__ == "__main__":
    # Test Ã§alÄ±ÅŸtÄ±rmasÄ±
    print("=" * 60)
    print("FinBERT Sentiment Analizi Test")
    print("=" * 60)
    
    # Mevcut haber dosyasÄ±nÄ± analiz et
    df = analyze_news_file()
    
    if not df.empty:
        # GÃ¼nlÃ¼k sentiment hesapla
        daily_sentiment = get_daily_sentiment(df)
        
        # GÃ¼nlÃ¼k sentiment kaydet
        daily_output = os.path.join(DATA_DIR, "daily_sentiment.csv")
        daily_sentiment.to_csv(daily_output, index=False)
        print(f"ðŸ’¾ GÃ¼nlÃ¼k sentiment kaydedildi: {daily_output}")
        
        print("\nðŸ“Š GÃ¼nlÃ¼k Sentiment Ã–rneÄŸi:")
        print(daily_sentiment.head(10))

